{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Heat Islands\n",
    "\n",
    "In this notebook we'll be exploring the urban heat island effect by looking at the impact on surface temperature of roof color. We'll be replicating the process described here: http://urbanspatialanalysis.com/urban-heat-islands-street-trees-in-philadelphia/ but using Python tools rather than ESRI.\n",
    "\n",
    "**Extra packages:** To run this notebook, you'll need the PyViz tools and a library of *top of atmosphere* calculations from [`rio-toa`](https://github.com/mapbox/rio-toa): `pip install rio-toa`\n",
    "\n",
    "To get all the requires packages run: `conda env create --file environment.yml`.\n",
    "\n",
    "**Data sources:** This notebook uses Landsat data from Google Cloud Storage as well as some geographic data from OpenDataPhilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "from geoviews.tile_sources import EsriImagery\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "hv.extension('bokeh', width=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some extra info about Landsat data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_info = pd.DataFrame([\n",
    "        (1,  \"Aerosol\", \" 0.43 - 0.45\",    0.440,  \"30\",         \"Coastal aerosol\"),\n",
    "        (2,  \"Blue\",    \" 0.45 - 0.51\",    0.480,  \"30\",         \"Blue\"),\n",
    "        (3,  \"Green\",   \" 0.53 - 0.59\",    0.560,  \"30\",         \"Green\"),\n",
    "        (4,  \"Red\",     \" 0.64 - 0.67\",    0.655,  \"30\",         \"Red\"),\n",
    "        (5,  \"NIR\",     \" 0.85 - 0.88\",    0.865,  \"30\",         \"Near Infrared (NIR)\"),\n",
    "        (6,  \"SWIR1\",   \" 1.57 - 1.65\",    1.610,  \"30\",         \"Shortwave Infrared (SWIR) 1\"),\n",
    "        (7,  \"SWIR2\",   \" 2.11 - 2.29\",    2.200,  \"30\",         \"Shortwave Infrared (SWIR) 2\"),\n",
    "        (8,  \"Panc\",    \" 0.50 - 0.68\",    0.590,  \"15\",         \"Panchromatic\"),\n",
    "        (9,  \"Cirrus\",  \" 1.36 - 1.38\",    1.370,  \"30\",         \"Cirrus\"),\n",
    "        (10, \"TIRS1\",   \"10.60 - 11.19\",   10.895, \"100 * (30)\", \"Thermal Infrared (TIRS) 1\"),\n",
    "        (11, \"TIRS2\",   \"11.50 - 12.51\",   12.005, \"100 * (30)\", \"Thermal Infrared (TIRS) 2\")],\n",
    "    columns=['Band', 'Name', 'Wavelength Range (µm)', 'Nominal Wavelength (µm)', 'Resolution (m)', 'Description']).set_index([\"Band\"])\n",
    "band_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "For this example, we will be using landsat data stored on Google Cloud Storage. We can use a list or urls to fetch only the bands that we need for these analyses. We use jinja template notation in intake to pass parameters to the `urlpath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('catalog.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the `google_landsat_band` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('catalog.yml') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following might feel a bit arbitrary, but we have chosen the path and row corresponding to the area over Philadelphia using the [earth explorer](https://earthexplorer.usgs.gov/). We have also found the product id of the particular date of interest using the same tool. With these values in hand, we can access parts of each file on Google Cloud Storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 14\n",
    "row = 32\n",
    "product_id = 'LC08_L1TP_014032_20160727_20170222_01_T1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to using intake is to initialize the catalog entry with user parameters to create a `data source`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = cat.google_landsat_band(path=path, row=row, product_id=product_id)\n",
    "data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this `data source` we can get a lazily loaded xarray object using dask. To make sure that we can inspect what dask is up to, it can be helpful to create a dask client\n",
    "\n",
    "### Optional: Create a Dask Client\n",
    "\n",
    "We can use this dask client to inspect what dask is spending time on and when tasks are actually running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Dask\n",
    "The data from the bands themselves are not loaded in this cell (that's why it doesn't take very long). Only some file metadata and the coordinates are loaded. For this workflow we don't ever need to load all the data into memory or onto disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_source.to_dask()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-setting to area of interest\n",
    "\n",
    "So far we haven't downloaded any band data. Since we know that we are interested in Philadelphia, we can just take a smaller square of data that covers the extents of the city. First we need to know the projection of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert that into a cartopy projection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ccrs.epsg(32618)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine what constitutes Philadelphia, we need some geometry to specify the bounds of the city. We can get a GeoJSON of neighborhood data from [OpenDataPhilly](https://www.opendataphilly.org/dataset/philadelphia-neighborhoods/resource/6c61f240-aafe-478e-b993-b75fd09a93d6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/azavea/geo-data/raw/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson'\n",
    "geoms = gpd.read_file(url)\n",
    "geoms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the bounds of each of these neighborhoods and then using min and max get a rectangle that encompasses all of Philly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = geoms.geometry.bounds\n",
    "bounds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_left_corner_lat_lon = bounds.minx.min(), bounds.miny.min()\n",
    "upper_right_corner_lat_lon = bounds.maxx.max(), bounds.maxy.max()\n",
    "\n",
    "print(lower_left_corner_lat_lon, upper_right_corner_lat_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `crs` defined above, we can transform these lat lons into map coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_corner = crs.transform_point(*lower_left_corner_lat_lon, ccrs.PlateCarree())\n",
    "ur_corner = crs.transform_point(*upper_right_corner_lat_lon, ccrs.PlateCarree())\n",
    "\n",
    "print(ll_corner, ur_corner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use those corners to slice the data. If the subset is empty along x or y, the ordering of the coordinates might not be what you anticipated. Try swapping the order of arguments in the slice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ds.sel(x=slice(ll_corner[0], ur_corner[0]), y=slice(ur_corner[1], ll_corner[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can persist this slice of the dataset in memory for easy use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.persist()\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we got the right area, we can do a simple plot of one of the bands and overlay the neighborhoods on top of it. We'll use [hvplot](https://hvplot.pyviz.org) to quickly create a [holoviews](https://holoviews.org) object rendered in [bokeh](https://bokeh.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_plot = subset.mean('band').hvplot(x='x', y='y', datashade=True, project=True, crs=crs, cmap='gray')\n",
    "hood_plot = geoms.hvplot(geo=True, alpha=.5, c='mapname', legend=False, frame_height=450)\n",
    "\n",
    "band_plot * hood_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at our map and ensured that the area covers the city, we will just take this chunk of the bands to use for further analyses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDVI\n",
    "\n",
    "We'll set up the calculation for NDVI but we won't yet do any computations - our bands are actually dask arrays, which allow for lazy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI = (subset.sel(band=5) - subset.sel(band=4)) / (subset.sel(band=5) + subset.sel(band=4))\n",
    "NDVI = NDVI.where(NDVI < np.inf)\n",
    "NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize NDVI, the data will need to be loaded and the NDVI computed. We can expect this to take some non-trivial amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI.hvplot(x='x', y='y', crs=crs, datashade=True, project=True, cmap='viridis', frame_height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate land surface temperature\n",
    "\n",
    "Given the NDVI calculated above, we can determine land surface temperature. For ease, we'll use some *top of atmosphere* calculations that have already been written up as Python functions as part of rasterio work in the `rio_toa` module. We'll also need to specify one more for transforming at satellite temperature (brightness temp) to land surface temperature. For these calculations we'll use both Thermal Infrared bands - 10 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rio_toa import brightness_temp, toa_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_surface_temp(BT, w, NDVI):\n",
    "    \"\"\"Calculate land surface temperature of Landsat 8\n",
    "    \n",
    "    temp = BT/1 + w * (BT /p) * ln(e)\n",
    "    \n",
    "    BT = At Satellite temperature (brightness)\n",
    "    w = wavelength of emitted radiance (μm)\n",
    "    \n",
    "    where p = h * c / s (1.439e-2 mK)\n",
    "    \n",
    "    h = Planck's constant (6.626e-34 Js)\n",
    "    s = Boltzmann constant (1.38e-23 J/K)\n",
    "    c = velocity of light (2.998e8 m/s)\n",
    "    \"\"\"\n",
    "    h = 6.626e-34\n",
    "    c = 2.998e8\n",
    "    s = 1.38e-23\n",
    "    \n",
    "    p = (h * c / s) * 1e6\n",
    "    \n",
    "    Pv = (NDVI - NDVI.min() / NDVI.max() - NDVI.min())**2\n",
    "    e = 0.004 * Pv + 0.986\n",
    "    \n",
    "    return BT / 1 + w * (BT / p) * np.log(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up a helper function to retrieve all the parameters from the metadata and general Landsat info table, and calculated the land surface temperature for band 10 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_surface_temp_for_band(band, data, units='F'):\n",
    "    # params from general Landsat info\n",
    "    w = band_info.loc[band]['Nominal Wavelength (µm)']\n",
    "    \n",
    "    # params from specific Landsat data text file for these images\n",
    "    ML = metadata[f'RADIANCE_MULT_BAND_{band}']\n",
    "    AL = metadata[f'RADIANCE_ADD_BAND_{band}']\n",
    "    K1 = metadata[f'K1_CONSTANT_BAND_{band}']\n",
    "    K2 = metadata[f'K2_CONSTANT_BAND_{band}']\n",
    "    \n",
    "    at_satellite_temp = brightness_temp.brightness_temp(data.sel(band=band).values, ML, AL, K1, K2)\n",
    "    \n",
    "    temp = land_surface_temp(at_satellite_temp, w, NDVI).compute()\n",
    "    return toa_utils.temp_rescale(temp, units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Metadata\n",
    "\n",
    "Every Landsat product has an associated metadata file containing parameters for these particular Landsat images. We'll write a helper function to get these parameters from the matlab.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_landsat_metadata(path, row, product_id):\n",
    "    \"\"\"Load Landsat metadata for path, row, product_id from Google Cloud Storage\n",
    "    \"\"\"\n",
    "    def parse_type(x):\n",
    "        try: \n",
    "            return eval(x)\n",
    "        except:\n",
    "            return x\n",
    "    \n",
    "    baseurl = 'https://storage.googleapis.com/gcp-public-data-landsat/LC08/01'\n",
    "    suffix = f'{path:03d}/{row:03d}/{product_id}/{product_id}_MTL.txt'\n",
    "    \n",
    "    df = intake.open_csv(\n",
    "        urlpath=f'{baseurl}/{suffix}',\n",
    "        csv_kwargs={'sep': '=',\n",
    "                    'header': None,\n",
    "                    'names': ['index', 'value'],\n",
    "                    'skiprows': 2,\n",
    "                    'converters': {'index': (lambda x: x.strip()),\n",
    "                                   'value': parse_type}}).read()\n",
    "    metadata = df.set_index('index')['value']\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_google_landsat_metadata(path, row, product_id)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **To Do:** Might be easier to read from the json as in the [dask geotiff example](https://examples.dask.org/applications/satellite-imagery-geotiff.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the functions to compute the land surface temperature for band 10 and band 11 - we'll combine these into on xarray object for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_10_f = land_surface_temp_for_band(10, subset)\n",
    "temp_11_f = land_surface_temp_for_band(11, subset)\n",
    "\n",
    "temp_f = xr.concat([temp_10_f, temp_11_f], \n",
    "                   dim=xr.DataArray([10,11], name='band', dims=['band']))\n",
    "temp_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results from the two different bands. Band 10 gets a higher temp over all, but the patterns of where the high temps occur seem similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_f.hvplot(x='x', y='y', groupby='band', cmap='fire_r', \n",
    "              crs=crs, rasterize=True, project=True, frame_height=450, \n",
    "              colorbar=False, clim=(70, 110)).layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the mean of the calculated land surface temperature for each of the bands and mimic the colormap used in the project that we are duplicating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp_f = temp_f.mean(dim='band')\n",
    "\n",
    "p = mean_temp_f.hvplot(x='x', y='y', title='Mean Surface Temp (F)', crs=crs, \n",
    "                       frame_height=450, project=True, cmap='rainbow', alpha=.5, legend=False)\n",
    "p * EsriImagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the hot spots are located over warehouse roofs and parking lots. This becomes even more visible when just the temperatures greater than 90F are displayed. To show this, we'll make a special colormap that just includes high intensity reds that are found at the top of the `fire_r` colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "\n",
    "special_cmap = cc.fire[::-1][90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_temp_p = (mean_temp_f.where(mean_temp_f > 90)\n",
    "    .hvplot(x='x', y='y', title='Mean Temp (F) > 90',\n",
    "            cmap=special_cmap, crs=crs, height=500, width=450, \n",
    "            colorbar=False, legend=False)\n",
    "    .redim(value='Temperature (F)'))\n",
    "\n",
    "thresholded_temp_p + thresholded_temp_p.options(alpha=.3) * EsriImagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we want the user to be able to set their own threshold and update the plot? Or what if we want to add in the street tree data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Notebook\n",
    "Since this notebook is getting unwieldy we can save off the mean temperature as an intermediary product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp_f.name = 'temperature'\n",
    "mtf_ds = mean_temp_f.to_dataset()\n",
    "\n",
    "mtf_ds.attrs['crs'] = subset.attrs['crs']\n",
    "mtf_ds.attrs['units'] = 'Fahrenheit'\n",
    "mtf_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will try to save data into the path. If data already exists in that location, it will fail."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mtf_ds.to_zarr('./data/mean_temp.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have saved our work and can move on to [the next notebook](02_trees.ipynb) to continue the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
